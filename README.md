# transformers-health-factchecking
Code and evaluation pipeline for benchmarking six Transformer models (BERT, RoBERTa, DistilBERT, ALBERT, XLNet, ELECTRA) on the Monant medical misinformation dataset.

# A Comparative Evaluation of Transformer Models for Health Misinformation Fact-Checking

This repository contains the implementation of the transformer-based classification experiments described in our paper:
"A Comparative Evaluation of Transformer Models for Health Misinformation Fact-Checking".

## Contents
- Jupyter Notebook for training and evaluation
- Instructions for reproducing results

## Dataset
This experiment uses the publicly available Monant dataset:
https://zenodo.org/records/5996864 

## Requirements
Python 3.10
Transformers, Torch, Pandas, Numpy, Scikit-learn

## How to run
1. Download dataset
2. Open the notebook on Kaggle 
3. Run all cells
